{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to install beautifulsoup4, requests, urllib \n",
    "- \"pip install beautifulsoup4\"\n",
    "- \"pip install requests\"\n",
    "- \"pip install urllib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request,sys,time\n",
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    try:\n",
    "        req = Request(url, headers = {'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urlopen(req).read()\n",
    "        page_soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "    except:\n",
    "        print(\"Error with parsing:\", url)\n",
    "    \n",
    "    return page_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(url):\n",
    "    page_links = []\n",
    "    for i in range(1, 810):\n",
    "        page_links.append(url + 'page/' + str(i) + '/')\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_page_links(url):\n",
    "    links = set()\n",
    "    try:\n",
    "        page_html = get_html(url)\n",
    "        articles = page_html.findAll(\"article\")\n",
    "    except:\n",
    "        print(\"Error with parsing:\", url)\n",
    "        return []\n",
    "    for article in articles:\n",
    "        try:\n",
    "            for link in article.select(\"a\"):\n",
    "                links.add(link['href'])\n",
    "        except:\n",
    "            continue\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_false_info(url):\n",
    "    false_phrase = ''\n",
    "    true_phrase = ''\n",
    "    count = 1\n",
    "    article_true_link = ''\n",
    "    \n",
    "    try:\n",
    "        page_soup = get_html(url)\n",
    "        false = page_soup.findAll(\"h1\", {\"class\": \"entry-title\"})\n",
    "        true = page_soup.findAll(\"p\", {\"class\": \"entry-content__text entry-content__text--explanation\"})\n",
    "        article_true_link = page_soup.find(\"a\", {\"class\": \"button entry-content__button entry-content__button--smaller\"}).get('href')\n",
    "        date = str(page_soup.find(\"p\", {\"class\": \"entry-content__text entry-content__text--topinfo\"}))[68:78]\n",
    "    except:\n",
    "        print(\"Error with url:\", url)\n",
    "    \n",
    "    try:\n",
    "        for phrase in false[0]:\n",
    "            if count == 3:\n",
    "                false_phrase = phrase\n",
    "            count += 1\n",
    "    except:\n",
    "        print('Error with false phrase')\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        count = 1\n",
    "        for phrase in true[0]:\n",
    "            if count == 1:\n",
    "                true_phrase = phrase\n",
    "            count += 1\n",
    "    except:\n",
    "        print('Error with true phrase')\n",
    "        return []\n",
    "    \n",
    "    return [false_phrase[1:], true_phrase[13:], article_true_link, date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statements(url):\n",
    "    pages = get_pages(url)\n",
    "    article_page_links = set()\n",
    "    page_count = 1\n",
    "    for page in pages:\n",
    "        print(\"This is page\", page_count)\n",
    "        article_page_links.update(get_article_page_links(page))\n",
    "        page_count += 1\n",
    "    true_false = dict()\n",
    "    link_count = 1\n",
    "    for link in article_page_links:\n",
    "        print(\"This is link\", link_count)\n",
    "        true_false[link] = get_true_false_info(link)\n",
    "        link_count += 1\n",
    "    return true_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_statements(true_false):\n",
    "    false = []\n",
    "    for statements in true_false.values():\n",
    "        false.append(statements[0])\n",
    "    return false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_statements(true_false):\n",
    "    true = []\n",
    "    for statements in true_false.values():\n",
    "        true.append(statements[1])\n",
    "    return true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(save_dict, name):\n",
    "    with open(name, 'w') as f:\n",
    "        f.write(\"Date; Article Link; False Statement; True Statement;\\n\")\n",
    "        for key in save_dict.keys():\n",
    "            f.write(\"%s; %s; %s; %s\\n\" % (save_dict[key][3], save_dict[key][2], save_dict[key][0], save_dict[key][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is page 1\n",
      "This is link 1\n",
      "This is link 2\n",
      "This is link 3\n",
      "This is link 4\n",
      "This is link 5\n",
      "This is link 6\n",
      "This is link 7\n",
      "This is link 8\n",
      "This is link 9\n",
      "This is link 10\n",
      "This is link 11\n",
      "This is link 12\n",
      "This is link 13\n",
      "This is link 14\n",
      "This is link 15\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    home_page_url = 'https://www.poynter.org/ifcn-covid-19-misinformation/'\n",
    "    statement_dict = get_statements(home_page_url)\n",
    "    save_csv(statement_dict, \"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
